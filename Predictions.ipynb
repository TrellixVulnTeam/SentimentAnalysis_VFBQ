{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_file = pd.read_csv('CleanedData.csv').copy()\n",
    "\n",
    "file_weighting = pd.DataFrame({'title': final_file[\"Cleaned_sentences\"].copy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>volunteer dies sheep charges therapy farm kim ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elusive truth behind attack french soccer star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>michael steinhardt billionaire surrenders mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>instagram says parental controls arrive march ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>biden supreme court commission prepares vote f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>elizabeth holmes says former boyfriend abused ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>math equation tried stump internet published s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>cardiac angiosarcoma virgil abloh celebrated f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>parag agrawal twitter new c e longtime twitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>breaking news pfizer biontech expected apply a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title\n",
       "0    volunteer dies sheep charges therapy farm kim ...\n",
       "1    elusive truth behind attack french soccer star...\n",
       "2    michael steinhardt billionaire surrenders mill...\n",
       "3    instagram says parental controls arrive march ...\n",
       "4    biden supreme court commission prepares vote f...\n",
       "..                                                 ...\n",
       "278  elizabeth holmes says former boyfriend abused ...\n",
       "279  math equation tried stump internet published s...\n",
       "280  cardiac angiosarcoma virgil abloh celebrated f...\n",
       "281  parag agrawal twitter new c e longtime twitter...\n",
       "282  breaking news pfizer biontech expected apply a...\n",
       "\n",
       "[283 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = pd.read_csv('sentiment_dictionary.csv')\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jul\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "tfidf.fit(file_weighting.title)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(file_weighting.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.title.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)#this step takes around 3-4 minutes minutes to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = file_weighting.title.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.title]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of sentiment from -1 to 1\n",
    "replacement_df['sentiment_rate'] = round(replacement_df['sentiment_rate']  / replacement_df['sentiment_rate'].abs().max(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_coeff</th>\n",
       "      <th>tfidf_scores</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_rate</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1.0081666286733688, 0, -0.994787010441699,...</td>\n",
       "      <td>[5.955827057601261, 4.857214768933151, 5.95582...</td>\n",
       "      <td>volunteer dies sheep charges therapy farm kim ...</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, -1.0086543665424563, 0, 0, -1.004287...</td>\n",
       "      <td>[5.955827057601261, 5.955827057601261, 5.95582...</td>\n",
       "      <td>elusive truth behind attack french soccer star...</td>\n",
       "      <td>-0.1391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, -1.0298857698935404, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5.955827057601261, 5.955827057601261, 5.95582...</td>\n",
       "      <td>michael steinhardt billionaire surrenders mill...</td>\n",
       "      <td>0.0643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, -1.0074632391552878, 0, 0, 0, 1.0086171207...</td>\n",
       "      <td>[5.955827057601261, 4.084024880699669, 5.55036...</td>\n",
       "      <td>instagram says parental controls arrive march ...</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.022014578520568, 0, 0.9969401802188572, 0, ...</td>\n",
       "      <td>[4.251078965362836, 5.039536325727106, 8.50215...</td>\n",
       "      <td>biden supreme court commission prepares vote f...</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>[0, 0, -1.0074632391552878, -1.014056444462660...</td>\n",
       "      <td>[5.2626798770413155, 11.100723898986192, 4.084...</td>\n",
       "      <td>elizabeth holmes says former boyfriend abused ...</td>\n",
       "      <td>-0.1627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>[0, 0, 0, 0, 1.019840496886929, 0, 0, 0, 0, 1....</td>\n",
       "      <td>[5.955827057601261, 5.955827057601261, 5.95582...</td>\n",
       "      <td>math equation tried stump internet published s...</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, -0.9902078445723124, 0, ...</td>\n",
       "      <td>[5.550361949493096, 5.955827057601261, 5.95582...</td>\n",
       "      <td>cardiac angiosarcoma virgil abloh celebrated f...</td>\n",
       "      <td>-0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>[0, 0, -1.0093933629118257, -1.009614047895300...</td>\n",
       "      <td>[5.955827057601261, 11.911654115202522, 10.525...</td>\n",
       "      <td>parag agrawal twitter new c e longtime twitter...</td>\n",
       "      <td>-0.1442</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>[0, 0, 0, 0, 1.000875666922396, 0, 0, -1.01858...</td>\n",
       "      <td>[5.550361949493096, 4.703064089105893, 5.95582...</td>\n",
       "      <td>breaking news pfizer biontech expected apply a...</td>\n",
       "      <td>0.1096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentiment_coeff  \\\n",
       "0    [0, 1.0081666286733688, 0, -0.994787010441699,...   \n",
       "1    [0, 0, 0, -1.0086543665424563, 0, 0, -1.004287...   \n",
       "2    [0, 0, 0, 0, -1.0298857698935404, 0, 0, 0, 0, ...   \n",
       "3    [0, -1.0074632391552878, 0, 0, 0, 1.0086171207...   \n",
       "4    [1.022014578520568, 0, 0.9969401802188572, 0, ...   \n",
       "..                                                 ...   \n",
       "278  [0, 0, -1.0074632391552878, -1.014056444462660...   \n",
       "279  [0, 0, 0, 0, 1.019840496886929, 0, 0, 0, 0, 1....   \n",
       "280  [0, 0, 0, 0, 0, 0, 0, -0.9902078445723124, 0, ...   \n",
       "281  [0, 0, -1.0093933629118257, -1.009614047895300...   \n",
       "282  [0, 0, 0, 0, 1.000875666922396, 0, 0, -1.01858...   \n",
       "\n",
       "                                          tfidf_scores  \\\n",
       "0    [5.955827057601261, 4.857214768933151, 5.95582...   \n",
       "1    [5.955827057601261, 5.955827057601261, 5.95582...   \n",
       "2    [5.955827057601261, 5.955827057601261, 5.95582...   \n",
       "3    [5.955827057601261, 4.084024880699669, 5.55036...   \n",
       "4    [4.251078965362836, 5.039536325727106, 8.50215...   \n",
       "..                                                 ...   \n",
       "278  [5.2626798770413155, 11.100723898986192, 4.084...   \n",
       "279  [5.955827057601261, 5.955827057601261, 5.95582...   \n",
       "280  [5.550361949493096, 5.955827057601261, 5.95582...   \n",
       "281  [5.955827057601261, 11.911654115202522, 10.525...   \n",
       "282  [5.550361949493096, 4.703064089105893, 5.95582...   \n",
       "\n",
       "                                              sentence  sentiment_rate  \\\n",
       "0    volunteer dies sheep charges therapy farm kim ...         -0.0120   \n",
       "1    elusive truth behind attack french soccer star...         -0.1391   \n",
       "2    michael steinhardt billionaire surrenders mill...          0.0643   \n",
       "3    instagram says parental controls arrive march ...          0.0671   \n",
       "4    biden supreme court commission prepares vote f...          0.1014   \n",
       "..                                                 ...             ...   \n",
       "278  elizabeth holmes says former boyfriend abused ...         -0.1627   \n",
       "279  math equation tried stump internet published s...          0.0330   \n",
       "280  cardiac angiosarcoma virgil abloh celebrated f...         -0.0044   \n",
       "281  parag agrawal twitter new c e longtime twitter...         -0.1442   \n",
       "282  breaking news pfizer biontech expected apply a...          0.1096   \n",
       "\n",
       "     prediction  \n",
       "0             0  \n",
       "1             0  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "..          ...  \n",
       "278           0  \n",
       "279           1  \n",
       "280           0  \n",
       "281           0  \n",
       "282           1  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df[['sentence', 'sentiment_rate', 'prediction']].to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  170  113\n",
       "1    0    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.600707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.600707\n",
       "precision  0.000000\n",
       "recall     0.000000\n",
       "f1         0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = replacement_df.prediction\n",
    "y_test = replacement_df.sentiment\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(replacement_df.sentiment, replacement_df.prediction))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
